{"cells":[{"cell_type":"markdown","metadata":{"id":"GSLV-moMDHvd"},"source":["**Navies Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJejt29l9h4o"},"outputs":[],"source":["import pandas as pd\n","import random\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdQfObqu9h4t"},"outputs":[],"source":["# Read the dataset\n","data = pd.read_csv(\"pima-indians-diabetes.csv\",header = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"elapsed":975,"status":"ok","timestamp":1600076203891,"user":{"displayName":"Appstek Innovative Labs","photoUrl":"","userId":"04728396421173214517"},"user_tz":-330},"id":"InJdfc0R9h4x","outputId":"379c76fc-80ef-45f6-8873-de6a98e62f70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pima Indians Diabetes Data Set\n","\n","   0    1   2   3    4     5      6   7  8\n","0  6  148  72  35    0  33.6  0.627  50  1\n","1  1   85  66  29    0  26.6  0.351  31  0\n","2  8  183  64   0    0  23.3  0.672  32  1\n","3  1   89  66  23   94  28.1  0.167  21  0\n","4  0  137  40  35  168  43.1  2.288  33  1\n"]}],"source":["# Visualize some data samples from the dataset\n","print('Pima Indians Diabetes Data Set\\n')\n","print(data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"elapsed":890,"status":"ok","timestamp":1600076207750,"user":{"displayName":"Appstek Innovative Labs","photoUrl":"","userId":"04728396421173214517"},"user_tz":-330},"id":"G6iquh2X9h42","outputId":"bcf05ffa-b557-4127-a4de-432d504d3bcc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\n","Stats for the 7 features over the dataset and the 2 classes {8th column}{diabetic/not-diabetic}\n","\n","                0           1           2  ...           6           7           8\n","count  768.000000  768.000000  768.000000  ...  768.000000  768.000000  768.000000\n","mean     3.845052  120.894531   69.105469  ...    0.471876   33.240885    0.348958\n","std      3.369578   31.972618   19.355807  ...    0.331329   11.760232    0.476951\n","min      0.000000    0.000000    0.000000  ...    0.078000   21.000000    0.000000\n","25%      1.000000   99.000000   62.000000  ...    0.243750   24.000000    0.000000\n","50%      3.000000  117.000000   72.000000  ...    0.372500   29.000000    0.000000\n","75%      6.000000  140.250000   80.000000  ...    0.626250   41.000000    1.000000\n","max     17.000000  199.000000  122.000000  ...    2.420000   81.000000    1.000000\n","\n","[8 rows x 9 columns]\n"]}],"source":["# 8th column is the class label\n","print('\\n\\n\\nStats for the 7 features over the dataset and the 2 classes {8th column}{diabetic/not-diabetic}\\n')\n","print(data.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3Sa69eT9h48"},"outputs":[],"source":["TRAIN_TEST_RATIO = 0.8        # 80% training data\n","picker = list(range(data.shape[0]))        # get all indices as a list\n","## sometimes the data is arranged classwise and not randomly\n","## therefore we shuffle the indices\n","random.shuffle(picker)\n","trainMax = int(data.shape[0] * TRAIN_TEST_RATIO)\n","\n","train_features = []\n","test_features = []\n","train_labels = []\n","test_labels = []\n","\n","for pick in picker[:trainMax]:\n","    train_features.append(data.values[pick][:-1])\n","    train_labels.append(int(data.values[pick][-1]))\n","for pick in picker[trainMax:]:\n","    test_features.append(data.values[pick][:-1])\n","    test_labels.append(int(data.values[pick][-1]))\n","\n","train_features = np.array(train_features)\n","test_features = np.array(test_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":962,"status":"ok","timestamp":1600076221013,"user":{"displayName":"Appstek Innovative Labs","photoUrl":"","userId":"04728396421173214517"},"user_tz":-330},"id":"76rpeyPE9h5A","outputId":"249d3ea8-9899-4112-85b2-1ccdba127d80"},"outputs":[{"data":{"text/plain":["array([4.00e+00, 1.48e+02, 6.00e+01, 2.70e+01, 3.18e+02, 3.09e+01,\n","       1.50e-01, 2.90e+01, 1.00e+00])"]},"execution_count":8,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["data.values[pick]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1079,"status":"ok","timestamp":1600076237410,"user":{"displayName":"Appstek Innovative Labs","photoUrl":"","userId":"04728396421173214517"},"user_tz":-330},"id":"pAE5_dPr9h5E","outputId":"62194639-929d-45c2-dd59-bafc4c8da322"},"outputs":[{"name":"stdout","output_type":"stream","text":["(614, 8) 614 (154, 8) 154\n"]}],"source":["print(train_features.shape, len(train_labels), test_features.shape, len(test_labels))"]},{"cell_type":"markdown","metadata":{"id":"IptlLvLc9h5I"},"source":["### Exercise 1: Calculate Prior $P(Y)$\n","\n","The formula for prior has been taught in class. This is also called the class probability. $P(Y)$ or $P(Y = y)$ is the fraction of the elements present in a class"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":971,"status":"ok","timestamp":1600076241755,"user":{"displayName":"Appstek Innovative Labs","photoUrl":"","userId":"04728396421173214517"},"user_tz":-330},"id":"_IMg5jCq9h5J","outputId":"276d2000-f29f-4626-b92a-ec3ee11bbcb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1]\n","[393 221]\n"]}],"source":["# Get the number of unique classes & corresponding number of elements belonging to each class\n","classes, counts = np.unique(train_labels, return_counts=True)\n","print(classes)\n","print(counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3dEFbBS9h5M"},"outputs":[],"source":["### I assume my classes are from 0 ... N for some N (Here, we have just 2 classes)\n","num_classes = len(classes)\n","num_feats = train_features.shape[1]  #total number of features\n","total_samples = len(train_labels)    #total number of samples"]},{"cell_type":"markdown","metadata":{"id":"srbcHWiJ9h5Q"},"source":["### **Exercise 1: Find the prior probability of each class as the list `prior`**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MoK6T-om9h5Q"},"outputs":[],"source":["# Prior for any class = {number of samples belonging to that class/ total_samples}\n","prior = np.array([ x*1.0/total_samples for x in counts ])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1081,"status":"ok","timestamp":1600076264897,"user":{"displayName":"Appstek Innovative Labs","photoUrl":"","userId":"04728396421173214517"},"user_tz":-330},"id":"TmwCypNw9h5U","outputId":"a2988762-6b2b-490e-b87b-1947f5a35e9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.64006515 0.35993485]\n"]}],"source":["print(prior)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lxCqIPGK9h5Y"},"outputs":[],"source":["## Calculate the mean and variance per feature dimension here \n","### from the training set from samples belonging to each class label.\n","\n","means = np.zeros((num_feats, num_classes)) # every feature, for each class\n","stddev = np.zeros((num_feats, num_classes)) # every feature, for each class\n","\n","# For each class\n","for y in classes: # selecting a class 'y'\n","    pts = train_features[np.where( train_labels == y )[0], :]    # get all samples belonging to 'y'\n","    # For each feature\n","    for i in range(num_feats):\n","        means[i, y] = np.mean(pts[:, i])\n","        stddev[i, y] = np.std(pts[:, i])\n","\n","### This completes the training phase\n","### We know have estimated both the prior probability and the posterior distributions from our training set."]},{"cell_type":"markdown","metadata":{"id":"LF6ixC9m9h5b"},"source":["\n","\n","### Exercise 2: Complete the Gaussian function ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UpR0eaoB9h5c"},"outputs":[],"source":["def gaussian(x, m, v):\n","    g = np.sqrt(1.0/2*np.pi*v*v)*np.exp( -1.0*(((x - m)/v)**2) )\n","    return g"]},{"cell_type":"markdown","metadata":{"id":"D32yu36Z9h5f"},"source":["### Exercise 3: Find the likelihood for each class 'y', once you have $P(X_{i}|y)$ from Exercise 2 ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"963ybUaa9h5g"},"outputs":[],"source":["def get_likelihood(point, means, stddev):\n","    \n","    feat_prob = np.zeros((num_feats, num_classes))\n","    for y in classes:\n","        for i in range(num_feats):\n","            feat_prob[i, y] = gaussian(point[i], means[i, y], stddev[i, y]) # get the probability\n","    \n","    likelihood = np.zeros((num_classes, 1)) # likelihood for each class 'y'\n","    for y in classes:\n","        # Take the product of all the feature likelihoods of the class considered\n","        likelihood[y] = np.prod(feat_prob[np.nonzero(feat_prob), y]) # mutliply for each feature 'Xi'\n","    \n","    return likelihood"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4ny5DMt9h5j"},"outputs":[],"source":["## Predict using Naive Bayes classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":927,"status":"ok","timestamp":1600076333238,"user":{"displayName":"Appstek Innovative Labs","photoUrl":"","userId":"04728396421173214517"},"user_tz":-330},"id":"MuCGE4wW9h5m","outputId":"26f9d7eb-3e25-4ae8-d7cd-ce24002b2a1b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n","  if __name__ == '__main__':\n"]}],"source":["predictions = []\n","# For each test sample\n","for i in range(len(test_labels)):\n","    \n","    # Get its likelihood of belong to either class\n","    likelihood = get_likelihood(test_features[i, :], means, stddev)\n","    \n","    # Calculate the approximate posterior = likelihood * prior\n","    approx_posterior = [ np.asscalar(x*y) for x,y in zip(likelihood, prior) ]\n","    #approx because of missing P(X) (constant) in the denominator\n","    \n","    # Make the prediction as that class with the maximum approximate posterior\n","    prediction = np.argmax(approx_posterior)\n","    predictions.append(prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":912,"status":"ok","timestamp":1600076337486,"user":{"displayName":"Appstek Innovative Labs","photoUrl":"","userId":"04728396421173214517"},"user_tz":-330},"id":"zf6qbyxX9h5p","outputId":"5693fb17-26f1-418f-ce05-1c7c7ec36578"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy\n","0.7142857142857143\n"]}],"source":["print(\"Accuracy\")\n","print(np.mean([x == y for x, y in zip(predictions, test_labels)]))"]},{"cell_type":"markdown","metadata":{"id":"ESFdIePtNVNf"},"source":["### Use same dataset and Implement using a scikit-learn libraries ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KX20Q14w9h5s"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgy-bd559h5v"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Assessment6.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"de805dbe6466896bd7cbe219080414257ec65ca3fc6df24513ccd1b91a22184a"}}},"nbformat":4,"nbformat_minor":0}
